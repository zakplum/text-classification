{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07c0a19",
   "metadata": {},
   "source": [
    "# Prototyping: Building a foundation\n",
    "****\n",
    "\n",
    "# Introduction\n",
    "\n",
    "For this prototype and in order to build a foundation and knowledge in Machine Learning, I will be following the \"Universal workflow of Machine Learning\" by Francoise Chollet detailed in Deep Learning with Python [1].\n",
    "\n",
    "In this workflow he presents a universal blueprint to solve any machine learning problem.\n",
    "\n",
    "What my personal aim is to achieve from this is to show proof of concept and my learning path given that my prior knowledge in Machine Learning is nil. For the work itself, I aim to provide \n",
    "a trained model using the Support Vector Machine algorithm to classify hatred related tweets.\n",
    "***\n",
    "\n",
    "# Methodology\n",
    "\n",
    "The universal workflow of Machine Learning is made up of seven different aspects: define the problem and assemble a dataset, choose a measure of success, decide on an evaluation protocol, prepare the data, develop a model that does better than the baseline, scale it up and regularise the model and tune the hyperparameters\n",
    "\n",
    "For the sake of providing a protoype we will only cover briefly defining the problem and assembling the dataset (aspect 1), measuring the success (aspect 2), preparing the data (aspect 4), training the model using built in SKLearn functions.\n",
    "\n",
    "The implementation of my specific project will look further at developing a model that does better than the baseline.  \n",
    "\n",
    "***\n",
    "\n",
    "## Aspect 1\n",
    "\n",
    "### Defining the problem\n",
    "\n",
    "***\n",
    "\n",
    "The input data for this prototype is called \"Twitter Sentiment Analysis\" from kaggle provided by Ali Toosi [2]. It contains two .csv files, one for testing and the other for training. The testing data is two columns consisting of ID and the tweet. The traning data has the addition of label which describes if the given tweet is racist/sexist it does so bar given it the value of \"0\" or \"1\". \n",
    "\n",
    "This is a binary classification as when we train the model and use the test data the predictions will be either of value 0 or 1. Identifying this problem type means we can make suitable choices on the models architecture. \n",
    "\n",
    "### Assembling the dataset\n",
    "\n",
    "First I will import pandas so we can import and read the train and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d663290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Training Data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Test Data\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe4d47",
   "metadata": {},
   "source": [
    "Let's take a look at the count of the data in the training file to see how many tweets we have that are deemed racist/sexist and those that are not. \n",
    "\n",
    "We will also ensure there is no missing values in our dataset and view the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbbe5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in the training data: 31962\n",
      "Total number of offensive tweets: 2242\n",
      "Total number of non-offensive tweets: 29720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total number of tweets in the training data:', train['tweet'].count())\n",
    "print('Total number of offensive tweets:', train[\"label\"].sum())\n",
    "print('Total number of non-offensive tweets:', len(train) - train[\"label\"].sum())\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0f8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('First 5 tweets:')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9822d",
   "metadata": {},
   "source": [
    "We can see that the entire length of the training data is 31,962. 2,242 tweets of which are considered offensive leaving 29,720 non-offensive. This should be a sufficient amount of data to train our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c48ab",
   "metadata": {},
   "source": [
    "## Aspect 2\n",
    "\n",
    "### The measure of success\n",
    "***\n",
    "\n",
    "A binary classification problem finds it's accuracy to be a common metric for success.  Accuracy will measure the proportion of correct predictions and is most useful when the class distributions are balanced. This means that each class has equal important. \n",
    "\n",
    "Other metrics you could use are: confusion matrix, precision and recall, f1-score and area under the receiver operating characteristic curvee (au-roc).\n",
    "\n",
    "## Aspect 4\n",
    "\n",
    "### Preparing the data\n",
    "***\n",
    "\n",
    "In this section, I am preprocessing the raw tweet data. It's crucial to apply these methods to the data to ensure that the performance of the model is optimal and suitable for analysis.\n",
    "\n",
    "We start with importing \"re\" for regular expressions and \"nltk\" (Natural Language Toolkit), which is a leading library for text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26972777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac3108",
   "metadata": {},
   "source": [
    "Next we define stopwords such as \"the\", \"is\" and \"in\", these are often removed at they carry minimal meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739f0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88897c",
   "metadata": {},
   "source": [
    "Next is creating and applying cleaning functions. \n",
    "\n",
    "These functions are lowercasing, removal of URLS, mentions, hashtags and punctuation. Finally, Tokenization and filtering the previously defined stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a5a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    filtered_words = [word for word in tweet_tokens if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "train['clean_tweet'] = train['tweet'].apply(clean_tweet)\n",
    "test['clean_tweet'] = test['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c4f29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks lyft credit cant use cause dont offer w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love u take u time urð ðððð ððð</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  father dysfunctional selfish drags kids dysfun...  \n",
       "1  thanks lyft credit cant use cause dont offer w...  \n",
       "2                                     bihday majesty  \n",
       "3              model love u take u time urð ðððð ððð  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the training dataset head to ensure clean_tweet has been added and processed correctly\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb87d4",
   "metadata": {},
   "source": [
    "After preprocessing the tweets, the next step is to split the data into training and testing sets.\n",
    "***\n",
    "Below we import train_test_split from Scikit-learn, this allows us to simplify the process of spliting into sets.\n",
    "\n",
    "We then execute the split with various parameters. These parameters are:\n",
    "\n",
    "- **train.clean_tweet.values**: Passes through the clean tweets\n",
    "- **y**: Our target labels\n",
    "- **stratify=y**: By setting this we ensure the distribution of offensive and non-offensive tweets are consistent in both the training and testing sets.\n",
    "- **random_state=1**: This is a seed for the random number generator. Using the same seed ensures that if we run the code again, we get the same split.\n",
    "- **test_size=0.3**: This specifies that 30% of the data should be allocated for the test set, and the remaining 70% for the training set.\n",
    "- **shuffle=True**: This shuffles the data before splitting, which is important for removing any inherent biases in the dataset order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1d2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = train.label.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1, \n",
    "                                                    test_size=0.3, shuffle=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b083516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train) + list(x_test))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# classify using support vector classifier\n",
    "svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
    "\n",
    "# perform classification and prediction on samples in x_test\n",
    "y_pred_svm = svm.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1710f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score for SVC is: \", round(accuracy_score(y_test, y_pred_svm) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeda4d9",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Chollet, F., 2018. Deep learning with Python. 1st ed. Shelter Islands: Manning, pp.111-116.\n",
    "\n",
    "[2] Toosi, A., 2018. Twitter Sentiment Analysis. [online] Kaggle.com. Available at: https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech [Accessed 2 December 2023]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523f47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
